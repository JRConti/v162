---
title: Subspace Learning for Effective Meta-Learning
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Meta-learning aims to extract meta-knowledge from historical tasks to accelerate
  learning on new tasks. Typical meta-learning algorithms like MAML learn a globally-shared
  meta-model for all tasks. However, when the task environments are complex, task
  model parameters are diverse and a common meta-model is insufficient to capture
  all the meta-knowledge. To address this challenge, in this paper, task model parameters
  are structured into multiple subspaces, and each subspace represents one type of
  meta-knowledge. We propose an algorithm to learn the meta-parameters (\ie, subspace
  bases). We theoretically study the generalization properties of the learned subspaces.
  Experiments on regression and classification meta-learning datasets verify the effectiveness
  of the proposed algorithm.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jiang22b
month: 0
tex_title: Subspace Learning for Effective Meta-Learning
firstpage: 10177
lastpage: 10194
page: 10177-10194
order: 10177
cycles: false
bibtex_author: Jiang, Weisen and Kwok, James and Zhang, Yu
author:
- given: Weisen
  family: Jiang
- given: James
  family: Kwok
- given: Yu
  family: Zhang
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/jiang22b/jiang22b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
