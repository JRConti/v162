---
title: Improving Transformers with Probabilistic Attention Keys
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Multi-head attention is a driving force behind state-of-the-art transformers,
  which achieve remarkable performance across a variety of natural language processing
  (NLP) and computer vision tasks. It has been observed that for many applications,
  those attention heads learn redundant embedding, and most of them can be removed
  without degrading the performance of the model. Inspired by this observation, we
  propose Transformer with a Mixture of Gaussian Keys (Transformer-MGK), a novel transformer
  architecture that replaces redundant heads in transformers with a mixture of keys
  at each head. These mixtures of keys follow a Gaussian mixture model and allow each
  attention head to focus on different parts of the input sequence efficiently. Compared
  to its conventional transformer counterpart, Transformer-MGK accelerates training
  and inference, has fewer parameters, and requires fewer FLOPs to compute while achieving
  comparable or better accuracy across tasks. Transformer-MGK can also be easily extended
  to use with linear attention. We empirically demonstrate the advantage of Transformer-MGK
  in a range of practical applications, including language modeling and tasks that
  involve very long sequences. On the Wikitext-103 and Long Range Arena benchmark,
  Transformer-MGKs with 4 heads attain comparable or better performance to the baseline
  transformers with 8 heads.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nguyen22c
month: 0
tex_title: Improving Transformers with Probabilistic Attention Keys
firstpage: 16595
lastpage: 16621
page: 16595-16621
order: 16595
cycles: false
bibtex_author: Nguyen, Tam Minh and Nguyen, Tan Minh and Le, Dung D. D. and Nguyen,
  Duy Khuong and Tran, Viet-Anh and Baraniuk, Richard and Ho, Nhat and Osher, Stanley
author:
- given: Tam Minh
  family: Nguyen
- given: Tan Minh
  family: Nguyen
- given: Dung D. D.
  family: Le
- given: Duy Khuong
  family: Nguyen
- given: Viet-Anh
  family: Tran
- given: Richard
  family: Baraniuk
- given: Nhat
  family: Ho
- given: Stanley
  family: Osher
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/nguyen22c/nguyen22c.pdf
extras:
- label: Other Files
  link: https://media.icml.cc/Conferences/ICML2022/other_files/nguyen22c-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
