---
title: The State of Sparse Training in Deep Reinforcement Learning
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: The use of sparse neural networks has seen rapid growth in recent years,
  particularly in computer vision. Their appeal stems largely from the reduced number
  of parameters required to train and store, as well as in an increase in learning
  efficiency. Somewhat surprisingly, there have been very few efforts exploring their
  use in Deep Reinforcement Learning (DRL). In this work we perform a systematic investigation
  into applying a number of existing sparse training techniques on a variety of DRL
  agents and environments. Our results corroborate the findings from sparse training
  in the computer vision domain {–}sparse networks perform better than dense networks
  for the same parameter count{–} in the DRL domain. We provide detailed analyses
  on how the various components in DRL are affected by the use of sparse networks
  and conclude by suggesting promising avenues for improving the effectiveness of
  sparse training methods, as well as for advancing their use in DRL.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: graesser22a
month: 0
tex_title: The State of Sparse Training in Deep Reinforcement Learning
firstpage: 7766
lastpage: 7792
page: 7766-7792
order: 7766
cycles: false
bibtex_author: Graesser, Laura and Evci, Utku and Elsen, Erich and Castro, Pablo Samuel
author:
- given: Laura
  family: Graesser
- given: Utku
  family: Evci
- given: Erich
  family: Elsen
- given: Pablo Samuel
  family: Castro
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/graesser22a/graesser22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
