---
title: Retrieval-Augmented Reinforcement Learning
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: 'Most deep reinforcement learning (RL) algorithms distill experience into
  parametric behavior policies or value functions via gradient updates. While effective,
  this approach has several disadvantages: (1) it is computationally expensive, (2)
  it can take many updates to integrate experiences into the parametric model, (3)
  experiences that are not fully integrated do not appropriately influence the agent’s
  behavior, and (4) behavior is limited by the capacity of the model. In this paper
  we explore an alternative paradigm in which we train a network to map a dataset
  of past experiences to optimal behavior. Specifically, we augment an RL agent with
  a retrieval process (parameterized as a neural network) that has direct access to
  a dataset of experiences. This dataset can come from the agent’s past experiences,
  expert demonstrations, or any other relevant source. The retrieval process is trained
  to retrieve information from the dataset that may be useful in the current context,
  to help the agent achieve its goal faster and more efficiently. The proposed method
  facilitates learning agents that at test time can condition their behavior on the
  entire dataset and not only the current state, or current trajectory. We integrate
  our method into two different RL agents: an offline DQN agent and an online R2D2
  agent. In offline multi-task problems, we show that the retrieval-augmented DQN
  agent avoids task interference and learns faster than the baseline DQN agent. On
  Atari, we show that retrieval-augmented R2D2 learns significantly faster than the
  baseline R2D2 agent and achieves higher scores. We run extensive ablations to measure
  the contributions of the components of our proposed method.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: goyal22a
month: 0
tex_title: Retrieval-Augmented Reinforcement Learning
firstpage: 7740
lastpage: 7765
page: 7740-7765
order: 7740
cycles: false
bibtex_author: Goyal, Anirudh and Friesen, Abram and Banino, Andrea and Weber, Theophane
  and Ke, Nan Rosemary and Badia, Adri{\`a} Puigdom{\`e}nech and Guez, Arthur and
  Mirza, Mehdi and Humphreys, Peter C and Konyushova, Ksenia and Valko, Michal and
  Osindero, Simon and Lillicrap, Timothy and Heess, Nicolas and Blundell, Charles
author:
- given: Anirudh
  family: Goyal
- given: Abram
  family: Friesen
- given: Andrea
  family: Banino
- given: Theophane
  family: Weber
- given: Nan Rosemary
  family: Ke
- given: Adrià Puigdomènech
  family: Badia
- given: Arthur
  family: Guez
- given: Mehdi
  family: Mirza
- given: Peter C
  family: Humphreys
- given: Ksenia
  family: Konyushova
- given: Michal
  family: Valko
- given: Simon
  family: Osindero
- given: Timothy
  family: Lillicrap
- given: Nicolas
  family: Heess
- given: Charles
  family: Blundell
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/goyal22a/goyal22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
