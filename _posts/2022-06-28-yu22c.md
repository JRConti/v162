---
title: How to Leverage Unlabeled Data in Offline Reinforcement Learning
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Offline reinforcement learning (RL) can learn control policies from static
  datasets but, like standard RL methods, it requires reward annotations for every
  transition. In many cases, labeling large datasets with rewards may be costly, especially
  if those rewards must be provided by human labelers, while collecting diverse unlabeled
  data might be comparatively inexpensive. How can we best leverage such unlabeled
  data in offline RL? One natural solution is to learn a reward function from the
  labeled data and use it to label the unlabeled data. In this paper, we find that,
  perhaps surprisingly, a much simpler method that simply applies zero rewards to
  unlabeled data leads to effective data sharing both in theory and in practice, without
  learning any reward model at all. While this approach might seem strange (and incorrect)
  at first, we provide extensive theoretical and empirical analysis that illustrates
  how it trades off reward bias, sample complexity and distributional shift, often
  leading to good results. We characterize conditions under which this simple strategy
  is effective, and further show that extending it with a simple reweighting approach
  can further alleviate the bias introduced by using incorrect reward labels. Our
  empirical evaluation confirms these findings in simulated robotic locomotion, navigation,
  and manipulation settings.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yu22c
month: 0
tex_title: How to Leverage Unlabeled Data in Offline Reinforcement Learning
firstpage: 25611
lastpage: 25635
page: 25611-25635
order: 25611
cycles: false
bibtex_author: Yu, Tianhe and Kumar, Aviral and Chebotar, Yevgen and Hausman, Karol
  and Finn, Chelsea and Levine, Sergey
author:
- given: Tianhe
  family: Yu
- given: Aviral
  family: Kumar
- given: Yevgen
  family: Chebotar
- given: Karol
  family: Hausman
- given: Chelsea
  family: Finn
- given: Sergey
  family: Levine
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/yu22c/yu22c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
