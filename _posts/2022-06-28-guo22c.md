---
title: Bounding Training Data Reconstruction in Private (Deep) Learning
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Differential privacy is widely accepted as the de facto method for preventing
  data leakage in ML, and conventional wisdom suggests that it offers strong protection
  against privacy attacks. However, existing semantic guarantees for DP focus on membership
  inference, which may overestimate the adversary’s capabilities and is not applicable
  when membership status itself is non-sensitive. In this paper, we derive the first
  semantic guarantees for DP mechanisms against training data reconstruction attacks
  under a formal threat model. We show that two distinct privacy accounting methods—Renyi
  differential privacy and Fisher information leakage—both offer strong semantic protection
  against data reconstruction attacks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo22c
month: 0
tex_title: Bounding Training Data Reconstruction in Private ({D}eep) Learning
firstpage: 8056
lastpage: 8071
page: 8056-8071
order: 8056
cycles: false
bibtex_author: Guo, Chuan and Karrer, Brian and Chaudhuri, Kamalika and Van Der Maaten,
  Laurens
author:
- given: Chuan
  family: Guo
- given: Brian
  family: Karrer
- given: Kamalika
  family: Chaudhuri
- given: Laurens
  family: Van Der Maaten
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/guo22c/guo22c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
