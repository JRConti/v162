---
title: Model-based Meta Reinforcement Learning using Graph Structured Surrogate Models
  and Amortized Policy Search
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Reinforcement learning is a promising paradigm for solving sequential decision-making
  problems, but low data efficiency and weak generalization across tasks are bottlenecks
  in real-world applications. Model-based meta reinforcement learning addresses these
  issues by learning dynamics and leveraging knowledge from prior experience. In this
  paper, we take a closer look at this framework and propose a new posterior sampling
  based approach that consists of a new model to identify task dynamics together with
  an amortized policy optimization step. We show that our model, called a graph structured
  surrogate model (GSSM), achieves competitive dynamics prediction performance with
  lower model complexity. Moreover, our approach in policy search is able to obtain
  high returns and allows fast execution by avoiding test-time policy gradient updates.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang22z
month: 0
tex_title: Model-based Meta Reinforcement Learning using Graph Structured Surrogate
  Models and Amortized Policy Search
firstpage: 23055
lastpage: 23077
page: 23055-23077
order: 23055
cycles: false
bibtex_author: Wang, Qi and Van Hoof, Herke
author:
- given: Qi
  family: Wang
- given: Herke
  family: Van Hoof
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/wang22z/wang22z.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
