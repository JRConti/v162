---
title: Adversarially trained neural representations are already as robust as biological
  neural representations
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Visual systems of primates are the gold standard of robust perception. There
  is thus a general belief that mimicking the neural representations that underlie
  those systems will yield artificial visual systems that are adversarially robust.
  In this work, we develop a method for performing adversarial visual attacks directly
  on primate brain activity. We then leverage this method to demonstrate that the
  above-mentioned belief might not be well-founded. Specifically, we report that the
  biological neurons that make up visual systems of primates exhibit susceptibility
  to adversarial perturbations that is comparable in magnitude to existing (robustly
  trained) artificial neural networks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo22d
month: 0
tex_title: Adversarially trained neural representations are already as robust as biological
  neural representations
firstpage: 8072
lastpage: 8081
page: 8072-8081
order: 8072
cycles: false
bibtex_author: Guo, Chong and Lee, Michael and Leclerc, Guillaume and Dapello, Joel
  and Rao, Yug and Madry, Aleksander and Dicarlo, James
author:
- given: Chong
  family: Guo
- given: Michael
  family: Lee
- given: Guillaume
  family: Leclerc
- given: Joel
  family: Dapello
- given: Yug
  family: Rao
- given: Aleksander
  family: Madry
- given: James
  family: Dicarlo
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/guo22d/guo22d.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
