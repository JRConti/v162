---
title: On Non-local Convergence Analysis of Deep Linear Networks
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: In this paper, we study the non-local convergence properties of deep linear
  networks. Specifically, under the quadratic loss, we consider optimizing deep linear
  networks in which there is at least a layer with only one neuron. We describe the
  convergent point of trajectories with an arbitrary balanced starting point under
  gradient flow, including the paths which converge to one of the saddle points. We
  also show specific convergence rates of trajectories that converge to the global
  minimizers by stages. We conclude that the rates vary from polynomial to linear.
  As far as we know, our results are the first to give a non-local analysis of deep
  linear neural networks with arbitrary balanced initialization, rather than the lazy
  training regime which has dominated the literature on neural networks or the restricted
  benign initialization.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen22p
month: 0
tex_title: On Non-local Convergence Analysis of Deep Linear Networks
firstpage: 3417
lastpage: 3443
page: 3417-3443
order: 3417
cycles: false
bibtex_author: Chen, Kun and Lin, Dachao and Zhang, Zhihua
author:
- given: Kun
  family: Chen
- given: Dachao
  family: Lin
- given: Zhihua
  family: Zhang
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/chen22p/chen22p.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
