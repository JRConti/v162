---
title: 'XAI for Transformers: Better Explanations through Conservative Propagation'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Transformers have become an important workhorse of machine learning, with
  numerous applications. This necessitates the development of reliable methods for
  increasing their transparency. Multiple interpretability methods, often based on
  gradient information, have been proposed. We show that the gradient in a Transformer
  reflects the function only locally, and thus fails to reliably identify the contribution
  of input features to the prediction. We identify Attention Heads and LayerNorm as
  main reasons for such unreliable explanations and propose a more stable way for
  propagation through these layers. Our proposal, which can be seen as a proper extension
  of the well-established LRP method to Transformers, is shown both theoretically
  and empirically to overcome the deficiency of a simple gradient-based approach,
  and achieves state-of-the-art explanation performance on a broad range of Transformer
  models and datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ali22a
month: 0
tex_title: "{XAI} for Transformers: Better Explanations through Conservative Propagation"
firstpage: 435
lastpage: 451
page: 435-451
order: 435
cycles: false
bibtex_author: Ali, Ameen and Schnake, Thomas and Eberle, Oliver and Montavon, Gr{\'e}goire
  and M{\"u}ller, Klaus-Robert and Wolf, Lior
author:
- given: Ameen
  family: Ali
- given: Thomas
  family: Schnake
- given: Oliver
  family: Eberle
- given: Grégoire
  family: Montavon
- given: Klaus-Robert
  family: Müller
- given: Lior
  family: Wolf
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/ali22a/ali22a.pdf
extras:
- label: Other Files
  link: https://media.icml.cc/Conferences/ICML2022/other_files/ali22a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
