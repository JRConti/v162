---
title: 'Iterative Hard Thresholding with Adaptive Regularization: Sparser Solutions
  Without Sacrificing Runtime'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We propose a simple modification to the iterative hard thresholding (IHT)
  algorithm, which recovers asymptotically sparser solutions as a function of the
  condition number. When aiming to minimize a convex function f(x) with condition
  number $\kappa$ subject to x being an s-sparse vector, the standard IHT guarantee
  is a solution with relaxed sparsity $O(s\kappa^2)$, while our proposed algorithm,
  regularized IHT, returns a solution with sparsity $O(s\kappa)$. Our algorithm significantly
  improves over ARHT [Axiotis & Sviridenko, 2021] which also achieves $O(s\kappa)$,
  as it does not require re-optimization in each iteration (and so is much faster),
  is deterministic, and does not require knowledge of the optimal solution value f(x*)
  or the optimal sparsity level s. Our main technical tool is an adaptive regularization
  framework, in which the algorithm progressively learns the weights of an l_2 regularization
  term that will allow convergence to sparser solutions. We also apply this framework
  to low rank optimization, where we achieve a similar improvement of the best known
  condition number dependence from $\kappa^2$ to $\kappa$.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: axiotis22a
month: 0
tex_title: 'Iterative Hard Thresholding with Adaptive Regularization: Sparser Solutions
  Without Sacrificing Runtime'
firstpage: 1175
lastpage: 1197
page: 1175-1197
order: 1175
cycles: false
bibtex_author: Axiotis, Kyriakos and Sviridenko, Maxim
author:
- given: Kyriakos
  family: Axiotis
- given: Maxim
  family: Sviridenko
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/axiotis22a/axiotis22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
