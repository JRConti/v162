---
title: Online Decision Transformer
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Recent work has shown that offline reinforcement learning (RL) can be formulated
  as a sequence modeling problem (Chen et al., 2021; Janner et al., 2021) and solved
  via approaches similar to large-scale language modeling. However, any practical
  instantiation of RL also involves an online component, where policies pretrained
  on passive offline datasets are finetuned via task-specific interactions with the
  environment. We propose Online Decision Transformers (ODT), an RL algorithm based
  on sequence modeling that blends offline pretraining with online finetuning in a
  unified framework. Our framework uses sequence-level entropy regularizers in conjunction
  with autoregressive modeling objectives for sample-efficient exploration and finetuning.
  Empirically, we show that ODT is competitive with the state-of-the-art in absolute
  performance on the D4RL benchmark but shows much more significant gains during the
  finetuning procedure.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zheng22c
month: 0
tex_title: Online Decision Transformer
firstpage: 27042
lastpage: 27059
page: 27042-27059
order: 27042
cycles: false
bibtex_author: Zheng, Qinqing and Zhang, Amy and Grover, Aditya
author:
- given: Qinqing
  family: Zheng
- given: Amy
  family: Zhang
- given: Aditya
  family: Grover
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/zheng22c/zheng22c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
