---
title: 'EqR: Equivariant Representations for Data-Efficient Reinforcement Learning'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We study a variety of notions of equivariance as an inductive bias in Reinforcement
  Learning (RL). In particular, we propose new mechanisms for learning representations
  that are equivariant to both the agentâ€™s action, as well as symmetry transformations
  of the state-action pairs. Whereas prior work on exploiting symmetries in deep RL
  can only incorporate predefined linear transformations, our approach allows non-linear
  symmetry transformations of state-action pairs to be learned from the data. This
  is achieved through 1) equivariant Lie algebraic parameterization of state and action
  encodings, 2) equivariant latent transition models, and 3) the incorporation of
  symmetry-based losses. We demonstrate the advantages of our method, which we call
  Equivariant representations for RL (EqR), for Atari games in a data-efficient setting
  limited to 100K steps of interactions with the environment.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mondal22a
month: 0
tex_title: "{E}q{R}: Equivariant Representations for Data-Efficient Reinforcement
  Learning"
firstpage: 15908
lastpage: 15926
page: 15908-15926
order: 15908
cycles: false
bibtex_author: Mondal, Arnab Kumar and Jain, Vineet and Siddiqi, Kaleem and Ravanbakhsh,
  Siamak
author:
- given: Arnab Kumar
  family: Mondal
- given: Vineet
  family: Jain
- given: Kaleem
  family: Siddiqi
- given: Siamak
  family: Ravanbakhsh
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/mondal22a/mondal22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
