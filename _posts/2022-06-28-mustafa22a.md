---
title: On the Generalization Analysis of Adversarial Learning
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Many recent studies have highlighted the susceptibility of virtually all
  machine-learning models to adversarial attacks. Adversarial attacks are imperceptible
  changes to an input example of a given prediction model. Such changes are carefully
  designed to alter the otherwise correct prediction of the model. In this paper,
  we study the generalization properties of adversarial learning. In particular, we
  derive high-probability generalization bounds on the adversarial risk in terms of
  the empirical adversarial risk, the complexity of the function class and the adversarial
  noise set. Our bounds are generally applicable to many models, losses, and adversaries.
  We showcase its applicability by deriving adversarial generalization bounds for
  the multi-class classification setting and various prediction models (including
  linear models and Deep Neural Networks). We also derive optimistic adversarial generalization
  bounds for the case of smooth losses. These are the first fast-rate bounds valid
  for adversarial deep learning to the best of our knowledge.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mustafa22a
month: 0
tex_title: On the Generalization Analysis of Adversarial Learning
firstpage: 16174
lastpage: 16196
page: 16174-16196
order: 16174
cycles: false
bibtex_author: Mustafa, Waleed and Lei, Yunwen and Kloft, Marius
author:
- given: Waleed
  family: Mustafa
- given: Yunwen
  family: Lei
- given: Marius
  family: Kloft
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/mustafa22a/mustafa22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
