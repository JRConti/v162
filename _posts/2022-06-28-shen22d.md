---
title: 'Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised Domain
  Adaptation'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We consider unsupervised domain adaptation (UDA), where labeled data from
  a source domain (e.g., photos) and unlabeled data from a target domain (e.g., sketches)
  are used to learn a classifier for the target domain. Conventional UDA methods (e.g.,
  domain adversarial training) learn domain-invariant features to generalize from
  the source domain to the target domain. In this paper, we show that contrastive
  pre-training, which learns features on unlabeled source and target data and then
  fine-tunes on labeled source data, is competitive with strong UDA methods. However,
  we find that contrastive pre-training does not learn domain-invariant features,
  diverging from conventional UDA intuitions. We show theoretically that contrastive
  pre-training can learn features that vary subtantially across domains but still
  generalize to the target domain, by disentangling domain and class information.
  We empirically validate our theory on benchmark vision datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shen22d
month: 0
tex_title: 'Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised
  Domain Adaptation'
firstpage: 19847
lastpage: 19878
page: 19847-19878
order: 19847
cycles: false
bibtex_author: Shen, Kendrick and Jones, Robbie M and Kumar, Ananya and Xie, Sang
  Michael and Haochen, Jeff Z. and Ma, Tengyu and Liang, Percy
author:
- given: Kendrick
  family: Shen
- given: Robbie M
  family: Jones
- given: Ananya
  family: Kumar
- given: Sang Michael
  family: Xie
- given: Jeff Z.
  family: Haochen
- given: Tengyu
  family: Ma
- given: Percy
  family: Liang
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/shen22d/shen22d.pdf
extras:
- label: Other Files
  link: https://media.icml.cc/Conferences/ICML2022/supplementary/shen22d-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
