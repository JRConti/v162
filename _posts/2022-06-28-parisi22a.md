---
title: The Unsurprising Effectiveness of Pre-Trained Vision Models for Control
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Recent years have seen the emergence of pre-trained representations as a
  powerful abstraction for AI applications in computer vision, natural language, and
  speech. However, policy learning for control is still dominated by a tabula-rasa
  learning paradigm, with visuo-motor policies often trained from scratch using data
  from deployment environments. In this context, we revisit and study the role of
  pre-trained visual representations for control, and in particular representations
  trained on large-scale computer vision datasets. Through extensive empirical evaluation
  in diverse control domains (Habitat, DeepMind Control, Adroit, Franka Kitchen),
  we isolate and study the importance of different representation training methods,
  data augmentations, and feature hierarchies. Overall, we find that pre-trained visual
  representations can be competitive or even better than ground-truth state representations
  to train control policies. This is in spite of using only out-of-domain data from
  standard vision datasets, without any in-domain data from the deployment environments.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: parisi22a
month: 0
tex_title: The Unsurprising Effectiveness of Pre-Trained Vision Models for Control
firstpage: 17359
lastpage: 17371
page: 17359-17371
order: 17359
cycles: false
bibtex_author: Parisi, Simone and Rajeswaran, Aravind and Purushwalkam, Senthil and
  Gupta, Abhinav
author:
- given: Simone
  family: Parisi
- given: Aravind
  family: Rajeswaran
- given: Senthil
  family: Purushwalkam
- given: Abhinav
  family: Gupta
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/parisi22a/parisi22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
