---
title: A Functional Information Perspective on Model Interpretation
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Contemporary predictive models are hard to interpret as their deep nets
  exploit numerous complex relations between input elements. This work suggests a
  theoretical framework for model interpretability by measuring the contribution of
  relevant features to the functional entropy of the network with respect to the input.
  We rely on the log-Sobolev inequality that bounds the functional entropy by the
  functional Fisher information with respect to the covariance of the data. This provides
  a principled way to measure the amount of information contribution of a subset of
  features to the decision function. Through extensive experiments, we show that our
  method surpasses existing interpretability sampling-based methods on various data
  signals such as image, text, and audio.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gat22a
month: 0
tex_title: A Functional Information Perspective on Model Interpretation
firstpage: 7266
lastpage: 7278
page: 7266-7278
order: 7266
cycles: false
bibtex_author: Gat, Itai and Calderon, Nitay and Reichart, Roi and Hazan, Tamir
author:
- given: Itai
  family: Gat
- given: Nitay
  family: Calderon
- given: Roi
  family: Reichart
- given: Tamir
  family: Hazan
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/gat22a/gat22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
