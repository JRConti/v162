---
title: 'BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language
  Understanding and Generation'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Vision-Language Pre-training (VLP) has advanced the performance for many
  vision-language tasks. However, most existing pre-trained models only excel in either
  understanding-based tasks or generation-based tasks. Furthermore, performance improvement
  has been largely achieved by scaling up the dataset with noisy image-text pairs
  collected from the web, which is a suboptimal source of supervision. In this paper,
  we propose BLIP, a new VLP framework which transfers flexibly to both vision-language
  understanding and generation tasks. BLIP effectively utilizes the noisy web data
  by bootstrapping the captions, where a captioner generates synthetic captions and
  a filter removes the noisy ones. We achieve state-of-the-art results on a wide range
  of vision-language tasks, such as image-text retrieval (+2.7% in average recall@1),
  image captioning (+2.8% in CIDEr), and VQA (+1.6% in VQA score). BLIP also demonstrates
  strong generalization ability when directly transferred to video-language tasks
  in a zero-shot manner. Code and models are available at https://github.com/salesforce/BLIP.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li22n
month: 0
tex_title: "{BLIP}: Bootstrapping Language-Image Pre-training for Unified Vision-Language
  Understanding and Generation"
firstpage: 12888
lastpage: 12900
page: 12888-12900
order: 12888
cycles: false
bibtex_author: Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven
author:
- given: Junnan
  family: Li
- given: Dongxu
  family: Li
- given: Caiming
  family: Xiong
- given: Steven
  family: Hoi
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/li22n/li22n.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
