---
title: 'Structure Preserving Neural Networks: A Case Study in the Entropy Closure
  of the Boltzmann Equation'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: In this paper, we explore applications of deep learning in statistical physics.
  We choose the Boltzmann equation as a typical example, where neural networks serve
  as a closure to its moment system. We present two types of neural networks to embed
  the convexity of entropy and to preserve the minimum entropy principle and intrinsic
  mathematical structures of the moment system of the Boltzmann equation. We derive
  an error bound for the generalization gap of convex neural networks which are trained
  in Sobolev norm and use the results to construct data sampling methods for neural
  network training. Numerical experiments demonstrate that the neural entropy closure
  is significantly faster than classical optimizers while maintaining sufficient accuracy.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schotthofer22a
month: 0
tex_title: 'Structure Preserving Neural Networks: A Case Study in the Entropy Closure
  of the Boltzmann Equation'
firstpage: 19406
lastpage: 19433
page: 19406-19433
order: 19406
cycles: false
bibtex_author: Schotth{\"o}fer, Steffen and Xiao, Tianbai and Frank, Martin and Hauck,
  Cory
author:
- given: Steffen
  family: Schotth√∂fer
- given: Tianbai
  family: Xiao
- given: Martin
  family: Frank
- given: Cory
  family: Hauck
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/schotthofer22a/schotthofer22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
