---
title: 'Human-in-the-loop: Provably Efficient Preference-based Reinforcement Learning
  with General Function Approximation'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We study human-in-the-loop reinforcement learning (RL) with trajectory preferences,
  where instead of receiving a numeric reward at each step, the RL agent only receives
  preferences over trajectory pairs from a human overseer. The goal of the RL agent
  is to learn the optimal policy which is most preferred by the human overseer. Despite
  the empirical success in various real-world applications, the theoretical understanding
  of preference-based RL (PbRL) is only limited to the tabular case. In this paper,
  we propose the first optimistic model-based algorithm for PbRL with general function
  approximation, which estimates the model using value-targeted regression and calculates
  the exploratory policies by solving an optimistic planning problem. We prove that
  our algorithm achieves the regret bound of $\tilde{O} (\operatorname{poly}(d H)
  \sqrt{K} )$, where $d$ is the complexity measure of the transition and preference
  model depending on the Eluder dimension and log-covering numbers, $H$ is the planning
  horizon, $K$ is the number of episodes, and $\tilde O(\cdot)$ omits logarithmic
  terms. Our lower bound indicates that our algorithm is near-optimal when specialized
  to the linear setting. Furthermore, we extend the PbRL problem by formulating a
  novel problem called RL with $n$-wise comparisons, and provide the first sample-efficient
  algorithm for this new setting. To the best of our knowledge, this is the first
  theoretical result for PbRL with (general) function approximation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen22ag
month: 0
tex_title: 'Human-in-the-loop: Provably Efficient Preference-based Reinforcement Learning
  with General Function Approximation'
firstpage: 3773
lastpage: 3793
page: 3773-3793
order: 3773
cycles: false
bibtex_author: Chen, Xiaoyu and Zhong, Han and Yang, Zhuoran and Wang, Zhaoran and
  Wang, Liwei
author:
- given: Xiaoyu
  family: Chen
- given: Han
  family: Zhong
- given: Zhuoran
  family: Yang
- given: Zhaoran
  family: Wang
- given: Liwei
  family: Wang
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/chen22ag/chen22ag.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
