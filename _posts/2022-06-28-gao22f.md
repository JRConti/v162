---
title: Generalizing Gaussian Smoothing for Random Search
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Gaussian smoothing (GS) is a derivative-free optimization (DFO) algorithm
  that estimates the gradient of an objective using perturbations of the current parameters
  sampled from a standard normal distribution. We generalize it to sampling perturbations
  from a larger family of distributions. Based on an analysis of DFO for non-convex
  functions, we propose to choose a distribution for perturbations that minimizes
  the mean squared error (MSE) of the gradient estimate. We derive three such distributions
  with provably smaller MSE than Gaussian smoothing. We conduct evaluations of the
  three sampling distributions on linear regression, reinforcement learning, and DFO
  benchmarks in order to validate our claims. Our proposal improves on GS with the
  same computational complexity, and are competitive with and usually outperform Guided
  ES and Orthogonal ES, two computationally more expensive algorithms that adapt the
  covariance matrix of normally distributed perturbations.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gao22f
month: 0
tex_title: Generalizing {G}aussian Smoothing for Random Search
firstpage: 7077
lastpage: 7101
page: 7077-7101
order: 7077
cycles: false
bibtex_author: Gao, Katelyn and Sener, Ozan
author:
- given: Katelyn
  family: Gao
- given: Ozan
  family: Sener
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/gao22f/gao22f.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
