---
title: 'The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions
  to Training Patterns via Spotlights of Attention'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Linear layers in neural networks (NNs) trained by gradient descent can be
  expressed as a key-value memory system which stores all training datapoints and
  the initial weights, and produces outputs using unnormalised dot attention over
  the entire training experience. While this has been technically known since the
  1960s, no prior work has effectively studied the operations of NNs in such a form,
  presumably due to prohibitive time and space complexities and impractical model
  sizes, all of them growing linearly with the number of training patterns which may
  get very large. However, this dual formulation offers a possibility of directly
  visualising how an NN makes use of training patterns at test time, by examining
  the corresponding attention weights. We conduct experiments on small scale supervised
  image classification tasks in single-task, multi-task, and continual learning settings,
  as well as language modelling, and discuss potentials and limits of this view for
  better understanding and interpreting how NNs exploit training patterns. Our code
  is public.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: irie22a
month: 0
tex_title: 'The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions
  to Training Patterns via Spotlights of Attention'
firstpage: 9639
lastpage: 9659
page: 9639-9659
order: 9639
cycles: false
bibtex_author: Irie, Kazuki and Csord{\'a}s, R{\'o}bert and Schmidhuber, J{\"u}rgen
author:
- given: Kazuki
  family: Irie
- given: Róbert
  family: Csordás
- given: Jürgen
  family: Schmidhuber
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/irie22a/irie22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
