---
title: Interactive Inverse Reinforcement Learning for Cooperative Games
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We study the problem of designing autonomous agents that can learn to cooperate
  effectively with a potentially suboptimal partner while having no access to the
  joint reward function. This problem is modeled as a cooperative episodic two-agent
  Markov decision process. We assume control over only the first of the two agents
  in a Stackelberg formulation of the game, where the second agent is acting so as
  to maximise expected utility given the first agent’s policy. How should the first
  agent act in order to learn the joint reward function as quickly as possible and
  so that the joint policy is as close to optimal as possible? We analyse how knowledge
  about the reward function can be gained in this interactive two-agent scenario.
  We show that when the learning agent’s policies have a significant effect on the
  transition function, the reward function can be learned efficiently.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: buning22a
month: 0
tex_title: Interactive Inverse Reinforcement Learning for Cooperative Games
firstpage: 2393
lastpage: 2413
page: 2393-2413
order: 2393
cycles: false
bibtex_author: B{\"u}ning, Thomas Kleine and George, Anne-Marie and Dimitrakakis,
  Christos
author:
- given: Thomas Kleine
  family: Büning
- given: Anne-Marie
  family: George
- given: Christos
  family: Dimitrakakis
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/buning22a/buning22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
