---
title: 'Contextual Bandits with Smooth Regret: Efficient Learning in Continuous Action
  Spaces'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Designing efficient general-purpose contextual bandit algorithms that work
  with large—or even infinite—action spaces would facilitate application to important
  scenarios such as information retrieval, recommendation systems, and continuous
  control. While obtaining standard regret guarantees can be hopeless, alternative
  regret notions have been proposed to tackle the large action setting. We propose
  a smooth regret notion for contextual bandits, which dominates previously proposed
  alternatives. We design a statistically and computationally efficient algorithm—for
  the proposed smooth regret—that works with general function approximation under
  standard supervised oracles. We also present an adaptive algorithm that automatically
  adapts to any smoothness level. Our algorithms can be used to recover the previous
  minimax/Pareto optimal guarantees under the standard regret, e.g., in bandit problems
  with multiple best arms and Lipschitz/H{ö}lder bandits. We conduct large-scale empirical
  evaluations demonstrating the efficacy of our proposed algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu22h
month: 0
tex_title: 'Contextual Bandits with Smooth Regret: Efficient Learning in Continuous
  Action Spaces'
firstpage: 27574
lastpage: 27590
page: 27574-27590
order: 27574
cycles: false
bibtex_author: Zhu, Yinglun and Mineiro, Paul
author:
- given: Yinglun
  family: Zhu
- given: Paul
  family: Mineiro
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/zhu22h/zhu22h.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
