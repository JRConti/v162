---
title: 'DepthShrinker: A New Compression Paradigm Towards Boosting Real-Hardware Efficiency
  of Compact Neural Networks'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: 'Efficient deep neural network (DNN) models equipped with compact operators
  (e.g., depthwise convolutions) have shown great potential in reducing DNNs’ theoretical
  complexity (e.g., the total number of weights/operations) while maintaining a decent
  model accuracy. However, existing efficient DNNs are still limited in fulfilling
  their promise in boosting real-hardware efficiency, due to their commonly adopted
  compact operators’ low hardware utilization. In this work, we open up a new compression
  paradigm for developing real-hardware efficient DNNs, leading to boosted hardware
  efficiency while maintaining model accuracy. Interestingly, we observe that while
  some DNN layers’ activation functions help DNNs’ training optimization and achievable
  accuracy, they can be properly removed after training without compromising the model
  accuracy. Inspired by this observation, we propose a framework dubbed DepthShrinker,
  which develops hardware-friendly compact networks via shrinking the basic building
  blocks of existing efficient DNNs that feature irregular computation patterns into
  dense ones with much improved hardware utilization and thus real-hardware efficiency.
  Excitingly, our DepthShrinker framework delivers hardware-friendly compact networks
  that outperform both state-of-the-art efficient DNNs and compression techniques,
  e.g., a 3.06% higher accuracy and 1.53x throughput on Tesla V100 over SOTA channel-wise
  pruning method MetaPruning. Our codes are available at: https://github.com/facebookresearch/DepthShrinker.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fu22c
month: 0
tex_title: "{D}epth{S}hrinker: A New Compression Paradigm Towards Boosting Real-Hardware
  Efficiency of Compact Neural Networks"
firstpage: 6849
lastpage: 6862
page: 6849-6862
order: 6849
cycles: false
bibtex_author: Fu, Yonggan and Yang, Haichuan and Yuan, Jiayi and Li, Meng and Wan,
  Cheng and Krishnamoorthi, Raghuraman and Chandra, Vikas and Lin, Yingyan
author:
- given: Yonggan
  family: Fu
- given: Haichuan
  family: Yang
- given: Jiayi
  family: Yuan
- given: Meng
  family: Li
- given: Cheng
  family: Wan
- given: Raghuraman
  family: Krishnamoorthi
- given: Vikas
  family: Chandra
- given: Yingyan
  family: Lin
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/fu22c/fu22c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
