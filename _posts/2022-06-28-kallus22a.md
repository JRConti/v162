---
title: Doubly Robust Distributionally Robust Off-Policy Evaluation and Learning
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Off-policy evaluation and learning (OPE/L) use offline observational data
  to make better decisions, which is crucial in applications where online experimentation
  is limited. However, depending entirely on logged data, OPE/L is sensitive to environment
  distribution shifts â€” discrepancies between the data-generating environment and
  that where policies are deployed. Si et al., (2020) proposed distributionally robust
  OPE/L (DROPE/L) to address this, but the proposal relies on inverse-propensity weighting,
  whose estimation error and regret will deteriorate if propensities are nonparametrically
  estimated and whose variance is suboptimal even if not. For standard, non-robust,
  OPE/L, this is solved by doubly robust (DR) methods, but they do not naturally extend
  to the more complex DROPE/L, which involves a worst-case expectation. In this paper,
  we propose the first DR algorithms for DROPE/L with KL-divergence uncertainty sets.
  For evaluation, we propose Localized Doubly Robust DROPE (LDR$^2$OPE) and show that
  it achieves semiparametric efficiency under weak product rates conditions. Thanks
  to a localization technique, LDR$^2$OPE only requires fitting a small number of
  regressions, just like DR methods for standard OPE. For learning, we propose Continuum
  Doubly Robust DROPL (CDR$^2$OPL) and show that, under a product rate condition involving
  a continuum of regressions, it enjoys a fast regret rate of $O(N^{-1/2})$ even when
  unknown propensities are nonparametrically estimated. We empirically validate our
  algorithms in simulations and further extend our results to general $f$-divergence
  uncertainty sets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kallus22a
month: 0
tex_title: Doubly Robust Distributionally Robust Off-Policy Evaluation and Learning
firstpage: 10598
lastpage: 10632
page: 10598-10632
order: 10598
cycles: false
bibtex_author: Kallus, Nathan and Mao, Xiaojie and Wang, Kaiwen and Zhou, Zhengyuan
author:
- given: Nathan
  family: Kallus
- given: Xiaojie
  family: Mao
- given: Kaiwen
  family: Wang
- given: Zhengyuan
  family: Zhou
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/kallus22a/kallus22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
