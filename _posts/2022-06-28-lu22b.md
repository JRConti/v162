---
title: Additive Gaussian Processes Revisited
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Gaussian Process (GP) models are a class of flexible non-parametric models
  that have rich representational power. By using a Gaussian process with additive
  structure, complex responses can be modelled whilst retaining interpretability.
  Previous work showed that additive Gaussian process models require high-dimensional
  interaction terms. We propose the orthogonal additive kernel (OAK), which imposes
  an orthogonality constraint on the additive functions, enabling an identifiable,
  low-dimensional representation of the functional relationship. We connect the OAK
  kernel to functional ANOVA decomposition, and show improved convergence rates for
  sparse computation methods. With only a small number of additive low-dimensional
  terms, we demonstrate the OAK model achieves similar or better predictive performance
  compared to black-box models, while retaining interpretability.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lu22b
month: 0
tex_title: Additive {G}aussian Processes Revisited
firstpage: 14358
lastpage: 14383
page: 14358-14383
order: 14358
cycles: false
bibtex_author: Lu, Xiaoyu and Boukouvalas, Alexis and Hensman, James
author:
- given: Xiaoyu
  family: Lu
- given: Alexis
  family: Boukouvalas
- given: James
  family: Hensman
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/lu22b/lu22b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
