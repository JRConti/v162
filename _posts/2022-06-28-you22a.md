---
title: 'ShiftAddNAS: Hardware-Inspired Search for More Accurate and Efficient Neural
  Networks'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Neural networks (NNs) with intensive multiplications (e.g., convolutions
  and transformers) are powerful yet power hungry, impeding their more extensive deployment
  into resource-constrained edge devices. As such, multiplication-free networks, which
  follow a common practice in energy-efficient hardware implementation to parameterize
  NNs with more efficient operators (e.g., bitwise shifts and additions), have gained
  growing attention. However, multiplication-free networks in general under-perform
  their vanilla counterparts in terms of the achieved accuracy. To this end, this
  work advocates hybrid NNs that consist of both powerful yet costly multiplications
  and efficient yet less powerful operators for marrying the best of both worlds,
  and proposes ShiftAddNAS, which can automatically search for more accurate and more
  efficient NNs. Our ShiftAddNAS highlights two enablers. Specifically, it integrates
  (1) the first hybrid search space that incorporates both multiplication-based and
  multiplication-free operators for facilitating the development of both accurate
  and efficient hybrid NNs; and (2) a novel weight sharing strategy that enables effective
  weight sharing among different operators that follow heterogeneous distributions
  (e.g., Gaussian for convolutions vs. Laplacian for add operators) and simultaneously
  leads to a largely reduced supernet size and much better searched networks. Extensive
  experiments and ablation studies on various models, datasets, and tasks consistently
  validate the effectiveness of ShiftAddNAS, e.g., achieving up to a +7.7% higher
  accuracy or a +4.9 better BLEU score as compared to state-of-the-art expert-designed
  and neural architecture searched NNs, while leading to up to 93% or 69% energy and
  latency savings, respectively. Codes and pretrained models are available at https://github.com/RICE-EIC/ShiftAddNAS.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: you22a
month: 0
tex_title: "{S}hift{A}dd{NAS}: Hardware-Inspired Search for More Accurate and Efficient
  Neural Networks"
firstpage: 25566
lastpage: 25580
page: 25566-25580
order: 25566
cycles: false
bibtex_author: You, Haoran and Li, Baopu and Huihong, Shi and Fu, Yonggan and Lin,
  Yingyan
author:
- given: Haoran
  family: You
- given: Baopu
  family: Li
- given: Shi
  family: Huihong
- given: Yonggan
  family: Fu
- given: Yingyan
  family: Lin
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/you22a/you22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
