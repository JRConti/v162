---
title: Delay-Adaptive Step-sizes for Asynchronous Learning
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: In scalable machine learning systems, model training is often parallelized
  over multiple nodes that run without tight synchronization. Most analysis results
  for the related asynchronous algorithms use an upper bound on the information delays
  in the system to determine learning rates. Not only are such bounds hard to obtain
  in advance, but they also result in unnecessarily slow convergence. In this paper,
  we show that it is possible to use learning rates that depend on the actual time-varying
  delays in the system. We develop general convergence results for delay-adaptive
  asynchronous iterations and specialize these to proximal incremental gradient descent
  and block coordinate descent algorithms. For each of these methods, we demonstrate
  how delays can be measured on-line, present delay-adaptive step-size policies, and
  illustrate their theoretical and practical advantages over the state-of-the-art.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wu22g
month: 0
tex_title: Delay-Adaptive Step-sizes for Asynchronous Learning
firstpage: 24093
lastpage: 24113
page: 24093-24113
order: 24093
cycles: false
bibtex_author: Wu, Xuyang and Magnusson, Sindri and Feyzmahdavian, Hamid Reza and
  Johansson, Mikael
author:
- given: Xuyang
  family: Wu
- given: Sindri
  family: Magnusson
- given: Hamid Reza
  family: Feyzmahdavian
- given: Mikael
  family: Johansson
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/wu22g/wu22g.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
