---
title: A Single-Loop Gradient Descent and Perturbed Ascent Algorithm for Nonconvex
  Functional Constrained Optimization
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Nonconvex constrained optimization problems can be used to model a number
  of machine learning problems, such as multi-class Neyman-Pearson classification
  and constrained Markov decision processes. However, such kinds of problems are challenging
  because both the objective and constraints are possibly nonconvex, so it is difficult
  to balance the reduction of the loss value and reduction of constraint violation.
  Although there are a few methods that solve this class of problems, all of them
  are double-loop or triple-loop algorithms, and they require oracles to solve some
  subproblems up to certain accuracy by tuning multiple hyperparameters at each iteration.
  In this paper, we propose a novel gradient descent and perturbed ascent (GDPA) algorithm
  to solve a class of smooth nonconvex inequality constrained problems. The GDPA is
  a primal-dual algorithm, which only exploits the first-order information of both
  the objective and constraint functions to update the primal and dual variables in
  an alternating way. The key feature of the proposed algorithm is that it is a single-loop
  algorithm, where only two step-sizes need to be tuned. We show that under a mild
  regularity condition GDPA is able to find Karush-Kuhn-Tucker (KKT) points of nonconvex
  functional constrained problems with convergence rate guarantees. To the best of
  our knowledge, it is the first single-loop algorithm that can solve the general
  nonconvex smooth problems with nonconvex inequality constraints. Numerical results
  also showcase the superiority of GDPA compared with the best-known algorithms (in
  terms of both stationarity measure and feasibility of the obtained solutions).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lu22a
month: 0
tex_title: A Single-Loop Gradient Descent and Perturbed Ascent Algorithm for Nonconvex
  Functional Constrained Optimization
firstpage: 14315
lastpage: 14357
page: 14315-14357
order: 14315
cycles: false
bibtex_author: Lu, Songtao
author:
- given: Songtao
  family: Lu
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/lu22a/lu22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
