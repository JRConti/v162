---
title: A Langevin-like Sampler for Discrete Distributions
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We propose discrete Langevin proposal (DLP), a simple and scalable gradient-based
  proposal for sampling complex high-dimensional discrete distributions. In contrast
  to Gibbs sampling-based methods, DLP is able to update all coordinates in parallel
  in a single step and the magnitude of changes is controlled by a stepsize. This
  allows a cheap and efficient exploration in the space of high-dimensional and strongly
  correlated variables. We prove the efficiency of DLP by showing that the asymptotic
  bias of its stationary distribution is zero for log-quadratic distributions, and
  is small for distributions that are close to being log-quadratic. With DLP, we develop
  several variants of sampling algorithms, including unadjusted, Metropolis-adjusted,
  stochastic and preconditioned versions. DLP outperforms many popular alternatives
  on a wide variety of tasks, including Ising models, restricted Boltzmann machines,
  deep energy-based models, binary neural networks and language generation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang22t
month: 0
tex_title: A {L}angevin-like Sampler for Discrete Distributions
firstpage: 26375
lastpage: 26396
page: 26375-26396
order: 26375
cycles: false
bibtex_author: Zhang, Ruqi and Liu, Xingchao and Liu, Qiang
author:
- given: Ruqi
  family: Zhang
- given: Xingchao
  family: Liu
- given: Qiang
  family: Liu
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/zhang22t/zhang22t.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
