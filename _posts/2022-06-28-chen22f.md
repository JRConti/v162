---
title: On the Sample Complexity of Learning Infinite-horizon Discounted Linear Kernel
  MDPs
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We study reinforcement learning for infinite-horizon discounted linear kernel
  MDPs, where the transition probability function is linear in a predefined feature
  mapping. Existing UCLK \citep{zhou2020provably} algorithm for this setting only
  has a regret guarantee, which cannot lead to a tight sample complexity bound. In
  this paper, we extend the uniform-PAC sample complexity from episodic setting to
  the infinite-horizon discounted setting, and propose a novel algorithm dubbed UPAC-UCLK
  that achieves an $\Tilde{O}\big(d^2/((1-\gamma)^4\epsilon^2)+1/((1-\gamma)^6\epsilon^2)\big)$
  uniform-PAC sample complexity, where $d$ is the dimension of the feature mapping,
  $\gamma \in(0,1)$ is the discount factor of the MDP and $\epsilon$ is the accuracy
  parameter. To the best of our knowledge, this is the first $\tilde{O}(1/\epsilon^2)$
  sample complexity bound for learning infinite-horizon discounted MDPs with linear
  function approximation (without access to the generative model).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen22f
month: 0
tex_title: On the Sample Complexity of Learning Infinite-horizon Discounted Linear
  Kernel {MDP}s
firstpage: 3149
lastpage: 3183
page: 3149-3183
order: 3149
cycles: false
bibtex_author: Chen, Yuanzhou and He, Jiafan and Gu, Quanquan
author:
- given: Yuanzhou
  family: Chen
- given: Jiafan
  family: He
- given: Quanquan
  family: Gu
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/chen22f/chen22f.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
