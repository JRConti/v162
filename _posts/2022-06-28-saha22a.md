---
title: 'Versatile Dueling Bandits: Best-of-both World Analyses for Learning from Relative
  Preferences'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We study the problem of $K$-armed dueling bandit for both stochastic and
  adversarial environments, where the goal of the learner is to aggregate information
  through relative preferences of pair of decision points queried in an online sequential
  manner. We first propose a novel reduction from any (general) dueling bandits to
  multi-armed bandits which allows us to improve many existing results in dueling
  bandits. In particular, <em>we give the first best-of-both world result for the
  dueling bandits regret minimization problem</em>—a unified framework that is guaranteed
  to perform optimally for both stochastic and adversarial preferences simultaneously.
  Moreover, our algorithm is also the first to achieve an optimal $O(\sum_{i = 1}^K
  \frac{\log T}{\Delta_i})$ regret bound against the Condorcet-winner benchmark, which
  scales optimally both in terms of the arm-size $K$ and the instance-specific suboptimality
  gaps $\{\Delta_i\}_{i = 1}^K$. This resolves the long standing problem of designing
  an instancewise gap-dependent order optimal regret algorithm for dueling bandits
  (with matching lower bounds up to small constant factors). We further justify the
  robustness of our proposed algorithm by proving its optimal regret rate under adversarially
  corrupted preferences—this outperforms the existing state-of-the-art corrupted dueling
  results by a large margin. In summary, we believe our reduction idea will find a
  broader scope in solving a diverse class of dueling bandits setting, which are otherwise
  studied separately from multi-armed bandits with often more complex solutions and
  worse guarantees. The efficacy of our proposed algorithms are empirically corroborated
  against state-of-the art dueling bandit methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: saha22a
month: 0
tex_title: 'Versatile Dueling Bandits: Best-of-both World Analyses for Learning from
  Relative Preferences'
firstpage: 19011
lastpage: 19026
page: 19011-19026
order: 19011
cycles: false
bibtex_author: Saha, Aadirupa and Gaillard, Pierre
author:
- given: Aadirupa
  family: Saha
- given: Pierre
  family: Gaillard
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/saha22a/saha22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
