---
title: When and How Mixup Improves Calibration
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: In many machine learning applications, it is important for the model to
  provide confidence scores that accurately capture its prediction uncertainty. Although
  modern learning methods have achieved great success in predictive accuracy, generating
  calibrated confidence scores remains a major challenge. Mixup, a popular yet simple
  data augmentation technique based on taking convex combinations of pairs of training
  examples, has been empirically found to significantly improve confidence calibration
  across diverse applications. However, when and how Mixup helps calibration is still
  a mystery. In this paper, we theoretically prove that Mixup improves calibration
  in <em>high-dimensional</em> settings by investigating natural statistical models.
  Interestingly, the calibration benefit of Mixup increases as the model capacity
  increases. We support our theories with experiments on common architectures and
  datasets. In addition, we study how Mixup improves calibration in semi-supervised
  learning. While incorporating unlabeled data can sometimes make the model less calibrated,
  adding Mixup training mitigates this issue and provably improves calibration. Our
  analysis provides new insights and a framework to understand Mixup and calibration.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang22f
month: 0
tex_title: When and How Mixup Improves Calibration
firstpage: 26135
lastpage: 26160
page: 26135-26160
order: 26135
cycles: false
bibtex_author: Zhang, Linjun and Deng, Zhun and Kawaguchi, Kenji and Zou, James
author:
- given: Linjun
  family: Zhang
- given: Zhun
  family: Deng
- given: Kenji
  family: Kawaguchi
- given: James
  family: Zou
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/zhang22f/zhang22f.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
