---
title: 'Sparse Double Descent: Where Network Pruning Aggravates Overfitting'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: People usually believe that network pruning not only reduces the computational
  cost of deep networks, but also prevents overfitting by decreasing model capacity.
  However, our work surprisingly discovers that network pruning sometimes even aggravates
  overfitting. We report an unexpected sparse double descent phenomenon that, as we
  increase model sparsity via network pruning, test performance first gets worse (due
  to overfitting), then gets better (due to relieved overfitting), and gets worse
  at last (due to forgetting useful information). While recent studies focused on
  the deep double descent with respect to model overparameterization, they failed
  to recognize that sparsity may also cause double descent. In this paper, we have
  three main contributions. First, we report the novel sparse double descent phenomenon
  through extensive experiments. Second, for this phenomenon, we propose a novel learning
  distance interpretation that the curve of l2 learning distance of sparse models
  (from initialized parameters to final parameters) may correlate with the sparse
  double descent curve well and reflect generalization better than minima flatness.
  Third, in the context of sparse double descent, a winning ticket in the lottery
  ticket hypothesis surprisingly may not always win.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: he22d
month: 0
tex_title: 'Sparse Double Descent: Where Network Pruning Aggravates Overfitting'
firstpage: 8635
lastpage: 8659
page: 8635-8659
order: 8635
cycles: false
bibtex_author: He, Zheng and Xie, Zeke and Zhu, Quanzhi and Qin, Zengchang
author:
- given: Zheng
  family: He
- given: Zeke
  family: Xie
- given: Quanzhi
  family: Zhu
- given: Zengchang
  family: Qin
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/he22d/he22d.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
