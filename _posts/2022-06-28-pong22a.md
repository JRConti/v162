---
title: Offline Meta-Reinforcement Learning with Online Self-Supervision
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Meta-reinforcement learning (RL) methods can meta-train policies that adapt
  to new tasks with orders of magnitude less data than standard RL, but meta-training
  itself is costly and time-consuming. If we can meta-train on offline data, then
  we can reuse the same static dataset, labeled once with rewards for different tasks,
  to meta-train policies that adapt to a variety of new tasks at meta-test time. Although
  this capability would make meta-RL a practical tool for real-world use, offline
  meta-RL presents additional challenges beyond online meta-RL or standard offline
  RL settings. Meta-RL learns an exploration strategy that collects data for adapting,
  and also meta-trains a policy that quickly adapts to data from a new task. Since
  this policy was meta-trained on a fixed, offline dataset, it might behave unpredictably
  when adapting to data collected by the learned exploration strategy, which differs
  systematically from the offline data and thus induces distributional shift. We propose
  a hybrid offline meta-RL algorithm, which uses offline data with rewards to meta-train
  an adaptive policy, and then collects additional unsupervised online data, without
  any reward labels to bridge this distribution shift. By not requiring reward labels
  for online collection, this data can be much cheaper to collect. We compare our
  method to prior work on offline meta-RL on simulated robot locomotion and manipulation
  tasks and find that using additional unsupervised online data collection leads to
  a dramatic improvement in the adaptive capabilities of the meta-trained policies,
  matching the performance of fully online meta-RL on a range of challenging domains
  that require generalization to new tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pong22a
month: 0
tex_title: Offline Meta-Reinforcement Learning with Online Self-Supervision
firstpage: 17811
lastpage: 17829
page: 17811-17829
order: 17811
cycles: false
bibtex_author: Pong, Vitchyr H and Nair, Ashvin V and Smith, Laura M and Huang, Catherine
  and Levine, Sergey
author:
- given: Vitchyr H
  family: Pong
- given: Ashvin V
  family: Nair
- given: Laura M
  family: Smith
- given: Catherine
  family: Huang
- given: Sergey
  family: Levine
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/pong22a/pong22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
