---
title: 'Pessimistic Q-Learning for Offline Reinforcement Learning: Towards Optimal
  Sample Complexity'
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: Offline or batch reinforcement learning seeks to learn a near-optimal policy
  using history data without active exploration of the environment. To counter the
  insufficient coverage and sample scarcity of many offline datasets, the principle
  of pessimism has been recently introduced to mitigate high bias of the estimated
  values. While pessimistic variants of model-based algorithms (e.g., value iteration
  with lower confidence bounds) have been theoretically investigated, their model-free
  counterparts — which do not require explicit model estimation — have not been adequately
  studied, especially in terms of sample efficiency. To address this inadequacy, we
  study a pessimistic variant of Q-learning in the context of finite-horizon Markov
  decision processes, and characterize its sample complexity under the single-policy
  concentrability assumption which does not require the full coverage of the state-action
  space. In addition, a variance-reduced pessimistic Q-learning algorithm is proposed
  to achieve near-optimal sample complexity. Altogether, this work highlights the
  efficiency of model-free algorithms in offline RL when used in conjunction with
  pessimism and variance reduction.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shi22c
month: 0
tex_title: 'Pessimistic Q-Learning for Offline Reinforcement Learning: Towards Optimal
  Sample Complexity'
firstpage: 19967
lastpage: 20025
page: 19967-20025
order: 19967
cycles: false
bibtex_author: Shi, Laixi and Li, Gen and Wei, Yuting and Chen, Yuxin and Chi, Yuejie
author:
- given: Laixi
  family: Shi
- given: Gen
  family: Li
- given: Yuting
  family: Wei
- given: Yuxin
  family: Chen
- given: Yuejie
  family: Chi
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/shi22c/shi22c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
