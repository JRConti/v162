---
title: An Analytical Update Rule for General Policy Optimization
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We present an analytical policy update rule that is independent of parametric
  function approximators. The policy update rule is suitable for optimizing general
  stochastic policies and has a monotonic improvement guarantee. It is derived from
  a closed-form solution to trust-region optimization using calculus of variation,
  following a new theoretical result that tightens existing bounds for policy improvement
  using trust-region methods. The update rule builds a connection between policy search
  methods and value function methods. Moreover, off-policy reinforcement learning
  algorithms can be derived from the update rule since it does not need to compute
  integration over on-policy states. In addition, the update rule extends immediately
  to cooperative multi-agent systems when policy updates are performed by one agent
  at a time.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li22d
month: 0
tex_title: An Analytical Update Rule for General Policy Optimization
firstpage: 12696
lastpage: 12716
page: 12696-12716
order: 12696
cycles: false
bibtex_author: Li, Hepeng and Clavette, Nicholas and He, Haibo
author:
- given: Hepeng
  family: Li
- given: Nicholas
  family: Clavette
- given: Haibo
  family: He
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/li22d/li22d.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
