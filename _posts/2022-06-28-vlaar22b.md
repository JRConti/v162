---
title: Multirate Training of Neural Networks
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: 'We propose multirate training of neural networks: partitioning neural network
  parameters into "fast" and "slow" parts which are trained on different time scales,
  where slow parts are updated less frequently. By choosing appropriate partitionings
  we can obtain substantial computational speed-up for transfer learning tasks. We
  show for applications in vision and NLP that we can fine-tune deep neural networks
  in almost half the time, without reducing the generalization performance of the
  resulting models. We analyze the convergence properties of our multirate scheme
  and draw a comparison with vanilla SGD. We also discuss splitting choices for the
  neural network parameters which could enhance generalization performance when neural
  networks are trained from scratch. A multirate approach can be used to learn different
  features present in the data and as a form of regularization. Our paper unlocks
  the potential of using multirate techniques for neural network training and provides
  several starting points for future work in this area.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: vlaar22b
month: 0
tex_title: Multirate Training of Neural Networks
firstpage: 22342
lastpage: 22360
page: 22342-22360
order: 22342
cycles: false
bibtex_author: Vlaar, Tiffany J and Leimkuhler, Benedict
author:
- given: Tiffany J
  family: Vlaar
- given: Benedict
  family: Leimkuhler
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/vlaar22b/vlaar22b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
