---
title: Differentiable Top-k Classification Learning
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: The top-k classification accuracy is one of the core metrics in machine
  learning. Here, k is conventionally a positive integer, such as 1 or 5, leading
  to top-1 or top-5 training objectives. In this work, we relax this assumption and
  optimize the model for multiple k simultaneously instead of using a single k. Leveraging
  recent advances in differentiable sorting and ranking, we propose a family of differentiable
  top-k cross-entropy classification losses. This allows training while not only considering
  the top-1 prediction, but also, e.g., the top-2 and top-5 predictions. We evaluate
  the proposed losses for fine-tuning on state-of-the-art architectures, as well as
  for training from scratch. We find that relaxing k not only produces better top-5
  accuracies, but also leads to top-1 accuracy improvements. When fine-tuning publicly
  available ImageNet models, we achieve a new state-of-the-art for these models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: petersen22a
month: 0
tex_title: Differentiable Top-k Classification Learning
firstpage: 17656
lastpage: 17668
page: 17656-17668
order: 17656
cycles: false
bibtex_author: Petersen, Felix and Kuehne, Hilde and Borgelt, Christian and Deussen,
  Oliver
author:
- given: Felix
  family: Petersen
- given: Hilde
  family: Kuehne
- given: Christian
  family: Borgelt
- given: Oliver
  family: Deussen
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/petersen22a/petersen22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
