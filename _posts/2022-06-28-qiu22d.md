---
title: Fast and Provable Nonconvex Tensor RPCA
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: In this paper, we study nonconvex tensor robust principal component analysis
  (RPCA) based on the $t$-SVD. We first propose an alternating projection method,
  i.e., APT, which converges linearly to the ground-truth under the incoherence conditions
  of tensors. However, as the projection to the low-rank tensor space in APT can be
  slow, we further propose to speedup such a process by utilizing the property of
  the tangent space of low-rank. The resulting algorithm, i.e., EAPT, is not only
  more efficient than APT but also keeps the linear convergence. Compared with existing
  tensor RPCA works, the proposed method, especially EAPT, is not only more effective
  due to the recovery guarantee and adaption in the transformed (frequency) domain
  but also more efficient due to faster convergence rate and lower iteration complexity.
  These benefits are also empirically verified both on synthetic data, and real applications,
  e.g., hyperspectral image denoising and video background subtraction.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: qiu22d
month: 0
tex_title: Fast and Provable Nonconvex Tensor {RPCA}
firstpage: 18211
lastpage: 18249
page: 18211-18249
order: 18211
cycles: false
bibtex_author: Qiu, Haiquan and Wang, Yao and Tang, Shaojie and Meng, Deyu and Yao,
  Quanming
author:
- given: Haiquan
  family: Qiu
- given: Yao
  family: Wang
- given: Shaojie
  family: Tang
- given: Deyu
  family: Meng
- given: Quanming
  family: Yao
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/qiu22d/qiu22d.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
